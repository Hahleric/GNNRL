import random

import numpy as np
from utils.cache_utils import cache_hit_ratio, cache_hit_ratio2
from utils.node_utils import get_edge_index, get_edge_attr
import random
import math
import torch

import random
import torch
import numpy as np
import math


class Cache:
    def __init__(self, file_id):
        self.file_id = file_id
        self.hits = 0


class Environment:
    def __init__(self, args, cache_size, test_items):
        """
        :param cache_size: cache size of the RSU, which is the only agent in our environment
        :param test_items: the sorted movie list by popularity, generated by recommender as well, it is
                            the sum of all movie rates, and sorted by the rate. Movies! not rates!
        """
        self.args = args
        self.cache_size = cache_size
        self.popular_files = test_items
        self.action_space = [0, 1]
        self.reward = 0
        self.cached_files = []
        self.init_n_veh = self.args.rl_batch_size
        self.init_n_node = 1 + self.init_n_veh
        self.init_edge_index = get_edge_index(self.init_n_veh)
        self.edge_index = self.init_edge_index.copy()
        self.init_edge_index = torch.tensor(self.init_edge_index, dtype=torch.long).t()

        if len(self.popular_files) == self.cache_size:
            self.cached_files = [Cache(file_id) for file_id in self.popular_files]
        else:
            self.cached_files = [Cache(file_id) for file_id in random.sample(self.popular_files, self.cache_size)]

        remaining_content = []
        for file_id in self.popular_files:
            if file_id not in [file.file_id for file in self.cached_files]:
                remaining_content.append(file_id)
        self.remaining_content = remaining_content
        self.init_cached_files = self.cached_files.copy()
        self.init_remaining_content = self.remaining_content.copy()
        self.init_state = np.zeros((1, self.args.feature_dim))
        self.state = self.init_state.copy()

    def step(self, action, rsu_embedding, request_dataset, v2i_rate, print_step, items_ready_to_cache):
        """
        :param action: action taken by the agent, generated by model
        :param request_dataset: a node feature array, shape(Covered_Vehicles, Requested_Movies)
        :param v2i_rate: vehicle to infrastructure rate of requesting vehicles, shape(Covered_Vehicles, )
        :return: state_, reward, cache_efficiency, request_delay
        """
        REPLAY_NUM = 20
        all_vehicle_request_num = len(request_dataset)
        if print_step == 0:
            self.cached_files = [Cache(file_id) for file_id in random.sample(items_ready_to_cache, self.cache_size)]

        if action == 1:
            num_to_replace = min(REPLAY_NUM, len(items_ready_to_cache), len(self.cached_files))
            if num_to_replace > 0:
                replace_content = [Cache(file_id) for file_id in random.sample(items_ready_to_cache, num_to_replace)]
                self.cached_files.sort(key=lambda x: x.hits)
                for i in range(num_to_replace):
                    self.cached_files[i] = replace_content[i]
            self.state = rsu_embedding

        cache_efficiency, cached_items = cache_hit_ratio(request_dataset, self.cached_files)
        cache_efficiency = cache_efficiency / 100
        self.cached_files = cached_items
        reward, request_delay = self.calculate_reward_and_delay(request_dataset, v2i_rate, cache_efficiency)
        if print_step % 50 == 0:
            print("---------------------------------------------")
            print('all_vehicle_request_num', all_vehicle_request_num)
            print('step:{} RSU1 cache_efficiency:{}'.format(print_step, cache_efficiency))
            print('step', print_step, 'request delay:%f' % request_delay)
            print('step', print_step, 'reward:%f' % reward)
            print("---------------------------------------------")
        return self.state, reward, cache_efficiency, request_delay

    def calculate_reward_and_delay(self, request_dataset, v2i_rate, cache_efficiency):
        reward = 0
        request_delay = 0
        for i in range(self.args.vehicle_num):
            vehicle_idx = i
            reward += cache_efficiency * math.exp(-0.0001 * 8000000 / v2i_rate[vehicle_idx]) * len(request_dataset)
            reward += (1 - cache_efficiency) * math.exp(-0.5999 * 8000000 / (v2i_rate[vehicle_idx] / 2)) * \
                      len(request_dataset)

            # Delay calculations adjusted to only account for cache_efficiency
            request_delay += cache_efficiency * len(request_dataset) / v2i_rate[vehicle_idx] * 800
            request_delay += (1 - cache_efficiency) * (
                    len(request_dataset) / (v2i_rate[vehicle_idx] / 2)) * 800

            # print(i,'mbs delay',(vehicle_request_num[vehicle_idx] / v2i_rate_mbs[vehicle_idx]) *100000)
        request_delay = request_delay / self.args.vehicle_num * 1000
        return reward, request_delay

    def reset(self):

        return (self.init_state,
                self.init_edge_index,
                self.init_remaining_content,
                )
