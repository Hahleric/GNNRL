import random

import numpy as np
from utils.cache_utils import cache_hit_ratio, cache_hit_ratio2
from utils.node_utils import get_edge_index, get_edge_attr
import random
import math
import torch


class Environment():
    def __init__(self, cache_size, popular_file, recommend_list):
        """
        :param cache_size: cache size of the RSU, which is the only agent in our environment
        :param popular_file: the sorted movie list by popularity, generated by recommender as well, it is
                            the sum of all movie rates, and sorted by the rate. Movies! not rates!
        :param recommend_list: popular contents generated by recommender system. It is a sorted list of
                            user preferred movies
        """
        self.cache_size = cache_size
        self.popular_file = popular_file
        self.action_space = [0, 1]
        self.reward = 0
        self.cached_files = []
        self.init_n_veh = recommend_list.shape[0]
        # MBS and RSU + initial number of vehicles
        self.init_n_node = 1 + self.init_n_veh
        self.init_edge_index = get_edge_index(self.init_n_veh)
        self.edge_index = self.init_edge_index.copy()
        self.init_edge_index = torch.tensor(self.init_edge_index, dtype=torch.long).t()
        if len(self.popular_file) <= self.cache_size:
            self.cached_files += self.popular_file

        if len(self.popular_file) > self.cache_size:
            self.cached_files += random.sample(list(self.popular_file), self.cache_size)
        print(self.cached_files)
        cache_files = []
        for i in range(len(self.popular_file)):
            # 按照内容流行度进行排序
            if self.popular_file[i] in self.cached_files:
                cache_files.append(self.popular_file[i])
        self.cached_files = cache_files

        remaining_content = []
        for i in range(len(self.popular_file)):
            if self.popular_file[i] not in self.cached_files:
                remaining_content.append(self.popular_file[i])
        self.remaining_content = remaining_content
        print('self.cache_size', self.cache_size)
        print('remaining contents', self.remaining_content)
        # recommend_list size (n, m), add first cache_size elements of every n row to state
        self.init_cached_files = self.cached_files.copy()
        self.init_remaining_content = self.remaining_content.copy()
        self.init_node_features = recommend_list
        self.init_node_features = np.insert(self.init_node_features, 0, popular_file, axis=0)
        self.node_features = self.init_node_features.copy()
        self.init_state = self.init_cached_files + self.init_remaining_content
        self.state = self.init_state.copy()

    def step(self, action, request_dataset, v2i_rate, print_step):
        """
        :param action: action taken by the agent, generated by model
        :param request_dataset: a node feature array, shape(Covered_Vehicles, Requested_Movies)
        :param v2i_rate: vehicle to infrastructure rate of requesting vehicles, shape(Covered_Vehicles, )
        :return: state_, reward, cache_efficiency, request_delay
        """
        # Const for replace num
        REPLAY_NUM = 10
        all_vehicle_request_num = 0
        print("action: ", action)
        for i in range(len(request_dataset)):
            all_vehicle_request_num += len(request_dataset[i])
        if action == 1:
            print("len(self.remaining_content)", len(self.remaining_content))
            num_to_replace = min(REPLAY_NUM, len(self.remaining_content), len(self.cached_files))

            if num_to_replace > 0:
                # 从剩余内容中随机选择文件作为替换内容
                replace_content = random.sample(list(self.remaining_content), num_to_replace)

                # 随机选择要替换的缓存文件的位置
                replace_indices = random.sample(range(len(self.cached_files)), num_to_replace)

                # 进行替换
                for index, content in zip(replace_indices, replace_content):
                    self.cached_files[index] = content

                # 更新remaining_content
                self.remaining_content = [file for file in self.remaining_content if file not in replace_content]

            cache_files = []
            for i in range(len(self.popular_file)):
                # 按照内容流行度进行排序
                if self.popular_file[i] in self.cached_files:
                    cache_files.append(self.popular_file[i])
            self.cached_files = cache_files

            last_content = []
            for i in range(len(self.popular_file)):
                if self.popular_file[i] not in self.cached_files:
                    last_content.append(self.popular_file[i])
            self.remaining_content = last_content

            # since we have to make state's dim is equal to vehicle's requests, we need to return this list
            self.state = self.cached_files + self.remaining_content

        cache_efficiency = cache_hit_ratio(request_dataset, self.cached_files,
                                           all_vehicle_request_num)
        cache_efficiency = cache_efficiency / 100

        reward = 0
        request_delay = 0
        for i in range(request_dataset.shape[0]):
            vehicle_idx = i

            # Only one cache efficiency calculation
            reward += cache_efficiency * math.exp(-0.0001 * 8000000 / v2i_rate[vehicle_idx]) * len(request_dataset[
                                                                                                       vehicle_idx])
            reward += (1 - cache_efficiency) * math.exp(-0.5999 * 8000000 / (v2i_rate[vehicle_idx] / 2)) * \
                      len(request_dataset[vehicle_idx])

            # Delay calculations adjusted to only account for cache_efficiency
            request_delay += cache_efficiency * len(request_dataset[vehicle_idx]) / v2i_rate[vehicle_idx] * 800
            request_delay += (1 - cache_efficiency) * (
                    len(request_dataset[vehicle_idx]) / (v2i_rate[vehicle_idx] / 2)) * 800

            # print(i,'mbs delay',(vehicle_request_num[vehicle_idx] / v2i_rate_mbs[vehicle_idx]) *100000)
        request_delay = request_delay / request_dataset.shape[0] * 1000
        # if print_step % 50 == 0:

        print("---------------------------------------------")
        # print("cached files", self.cached_files)
        print('all_vehicle_request_num', all_vehicle_request_num)
        print('step:{} RSU1 cache_efficiency:{}'.format(print_step, cache_efficiency))
        print('step', print_step, 'request delay:%f' % (request_delay))
        print('step', print_step, 'reward:%f' % (reward))
        print("---------------------------------------------")
        return self.state, reward, cache_efficiency, request_delay

    def reset(self):
        return (self.init_state,
                self.init_edge_index,
                self.init_remaining_content,
                self.init_node_features,
                )
